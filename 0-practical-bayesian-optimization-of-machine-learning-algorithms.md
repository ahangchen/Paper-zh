# 机器学习算法贝叶斯优化实践
## 摘要
使用机器学习算法经常需要小心地调参（学习参数或者模型参数）。不幸的是，这种调节往往是需要专业经验，运气，或者一些暴力搜索，这些东西构成的黑魔法。因此，能够优化任何给出的学习算法的自动调参有着巨大的吸引力，在这篇文章中，我们在贝叶斯优化的角度考虑这个问题，学习算法泛化的性能由高斯过程来模拟。我们说明了几种高斯过程本质，比如内核类型，和对超参数的处理，可能在获取一个好的优化器这个问题上可以达到专家级的表现。我们描述了新的算法，考虑变量在学习算法实验中的代价（周期），这可以在多核并行实验作为表征。我们展示了这些合适的算法优化了先前的自动化过程，并且在许多算法上达到甚至超过了人类专家级优化，包裹LDA，SVM，CNN。
## 1 介绍
机器学习算法几乎没有参数无关的：参数控制来学习率，模型的容量，都需要指定。通常认为这些参数是一种麻烦。人们倾向于发展拥有更少参数的机器学习算法。另一方面，这个话题另一种灵活的方式是，将超参数的优化视为一个自动化过程。特别的，我们可以将这种优化视为一个未知黑箱函数，然后调用处理这种问题的算法。一个好的选择是贝叶斯优化，已经在大量挑战性的优化问题上证明它比其他全局优化算法更佳。对于连续函数，贝叶斯优化通常通过假设未知函数被一个高斯过程筛选过并且为这个函数维护一个后分布作为观察，或者，在我们的例子里，用不同的参数运行学习算法实验。为了挑选下一个实验的参数，我们可以在当前最好结果上优化期望提高（EI）或者优化高斯过程的上置信度（UCB）。EI和UCB在大量寻找全局最优问题的多模黑箱函数评估问题上被证明有效。

机器学习算法，然而，有着特定的与其他黑箱优化问题不同的特征。首先，每个函数评估需要大量的时间，训练一个有着10个隐含单元的小型神经网络需要的时间比一个更大的有着1000个隐含单元的神经网络消耗更少的时间。即使不考虑耗时，云计算的出现使得需要的大内存学习机器，改变了不同隐含单元所需的实际经济价值。其次，机器学习实验通常是并行的，多核或多机的。在这些情况中，标准顺序GP优化过程可能不理想。

在这篇文章中，我们实践了好的机器学习算法贝叶斯优化。我们证明，基于GP超参数的优化比基于GP内核的优化要更好，正如前面所说的。我们第二个贡献是描述了新的算法，考虑了变量和实验的未知代价，以及多核可用性以并行运行实验。

高斯过程已经被证明在计算实验的代理模型上有效，基于此，合适性分析，标准化和预测的实践被建立起来。这些策略在优化的时候却不被考虑，实际上，这些对于机器学习研究者理解不同参数时模型的有效性很有帮助。哈特已经发展了一个顺序的基于模型的优化策略，以以设置满意度，用随机森林混合整数编程。然而我们考虑的机器学习算法，构造一个完全贝叶斯手段，因他们昂贵的自然必要性以最小化评估的时间。贝叶斯优化策略也被用于调节蒙特卡洛算法的超参数。最近本格斯特拉已经探索了大量优化机器学习算法的策略。他们证明网格搜索策略比随机搜索差，建议使用高斯过程贝叶斯优化以优化一个平方到指数的分布，和TPA。

## 2 高斯过程优先的贝叶斯优化
由于在其他类型的优化中，在贝叶斯优化里，我们感兴趣的是找到一个函数在自变量的某个范围内的最小值，我们会把他作为R^D的自己。让贝叶斯优化和其他过程不同的是他构建了f(x)的一个概率模型，然后推导这个模型以决定下一个评估函数的自变量区间在哪里，同时集成不确定性。关键的逻辑是，使用上一次f(x)评估中所有的可用的信息，而非仅仅依赖于局部梯度和hessian近似。这导致一个能用相对少得多的步骤找到困难非凸函数的最小值的过程，代价是决定下一个要尝试的点需要的计算更多了。当评估f(x)执行起来很昂贵的时候，也就是需要训练机器学习算法的时候，容易调整一些额外的计算以取得更好的决策，从贝叶斯优化规范注意的大方向上，以及先前工作的回顾看。在这个部分，我们简单地回顾了通常的贝叶斯优化途径，在第三部分我们将讨论我们的创新性贡献。

### 2.1 高斯过程
高斯过程是一个方便而强大的函数优先分布，我们在这里用它作为这个表达式：f：X -> R。高斯过程由任意有限N个点的集合{Xn ∈ X}定义，推导出多变量的RN空间上的高斯分布。第n个点被作为f(xn)的函数值，高斯分布优雅的边缘化属性允许我们计算边缘，以闭合的形式计算各种情况。函数结果的分布的支持和属性由一个平均函数m: X -> R决定，以及一个正定分布函数K: X * X -> R。我们会在section3.1 讨论分布函数的影响。作为高斯过程的一个概览，参考Rasmussen和Williams。

### 2.2 贝叶斯优化的获取函数
我们假设函数f(x)有一个高斯过程优先绘制，我们的的观察是{Xn, yn}的形式，yn ~ N(f(xn), v), v是引入函数观察中的噪声的方差。这个优先因子和这些数据导出了一个函数的落后因子，也就是获取函数，我们定义为a：X->R+，通过一个代理优化Xnext = argmax(a(x))决定了X中的哪些点需要在下一次评估，并且多个不同的函数已被得到推荐。通常，这些获取函数依赖于先前的观察，包括GP超参数，我们定义这种以来为a(x;{Xn,yn}, θ)。有几种流行的获取函数的选择。在高斯过程优先中，这些函数仅仅通过预测均值函数μ(X; {Xn,yn}, θ)和预测方差函数对函数依赖于模型。在处理过程中，我们将会定义最好的当前值为Xbest = argminxn f(xn), 以及用标准格式定义累计分布函数为Φ(·)。

**提升的可能性** 一种直观的策略是在当前的最佳值之上最大化提升概率。在GP的情况下，这种情况可以分析计算：

> 原文第三页2.2 

**期望提升** 另一种可选图形，我们可以选择在当前最佳值上获得最大化期望提升。这在高斯过程下也有闭合形式。

> 原文第三页2.2 

**GP上置信度** 一个最近的发展是，探索更低的置信边界（上界，认为是最值）以构建最小化优化过程中最小化反悔程度的函数。这类获取函数有着这样的形式：

> 原文第三页2.2 

有着可调的k以平衡操作与探索。

在这篇文章中我们会关注EI标准，因为它被证明比概率可能性要好，但不像GP上置信度，它不需要有自己的调节参数，尽管EI算法在最小化问题上运行得很好，我们希望记下反悔形式可能在某些设置下更加适合。我们在Setion4.1做了基于EI和GP-UCB的比较。


