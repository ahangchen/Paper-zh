# 机器学习算法贝叶斯优化实践
## 摘要
使用机器学习算法经常需要小心地调参（学习参数或者模型参数）。不幸的是，这种调节往往是需要专业经验，运气，或者一些暴力搜索，这些东西构成的黑魔法。因此，能够优化任何给出的学习算法的自动调参有着巨大的吸引力，在这篇文章中，我们在贝叶斯优化的角度考虑这个问题，学习算法泛化的性能由高斯过程来模拟。我们说明了几种高斯过程本质，比如内核类型，和对超参数的处理，可能在获取一个好的优化器这个问题上可以达到专家级的表现。我们描述了新的算法，考虑变量在学习算法实验中的代价（周期），这可以在多核并行实验作为表征。我们展示了这些合适的算法优化了先前的自动化过程，并且在许多算法上达到甚至超过了人类专家级优化，包裹LDA，SVM，CNN。
## 1 介绍
机器学习算法几乎没有参数无关的：参数控制来学习率，模型的容量，都需要指定。通常认为这些参数是一种麻烦。人们倾向于发展拥有更少参数的机器学习算法。另一方面，这个话题另一种灵活的方式是，将超参数的优化视为一个自动化过程。特别的，我们可以将这种优化视为一个未知黑箱函数，然后调用处理这种问题的算法。一个好的选择是贝叶斯优化，已经在大量挑战性的优化问题上证明它比其他全局优化算法更佳。对于连续函数，贝叶斯优化通常通过假设未知函数被一个高斯过程筛选过并且为这个函数维护一个后分布作为观察，或者，在我们的例子里，用不同的参数运行学习算法实验。为了挑选下一个实验的参数，我们可以在当前最好结果上优化期望提高（EI）或者优化高斯过程的上置信度（UCB）。EI和UCB在大量寻找全局最优问题的多模黑箱函数评估问题上被证明有效。

机器学习算法，然而，有着特定的与其他黑箱优化问题不同的特征。首先，每个函数评估需要大量的时间，训练一个有着10个隐含单元的小型神经网络需要的时间比一个更大的有着1000个隐含单元的神经网络消耗更少的时间。即使不考虑耗时，云计算的出现使得需要的大内存学习机器，改变了不同隐含单元所需的实际经济价值。其次，机器学习实验通常是并行的，多核或多机的。在这些情况中，标准顺序GP优化过程可能不理想。

在这篇文章中，我们实践了好的机器学习算法贝叶斯优化。我们证明，基于GP超参数的优化比基于GP内核的优化要更好，正如前面所说的。我们第二个贡献是描述了新的算法，考虑了变量和实验的未知代价，以及多核可用性以并行运行实验。

高斯过程已经被证明在计算实验的代理模型上有效，基于此，合适性分析，标准化和预测的实践被建立起来。这些策略在优化的时候却不被考虑，实际上，这些对于机器学习研究者理解不同参数时模型的有效性很有帮助。哈特已经发展了一个顺序的基于模型的优化策略，以以设置满意度，用随机森林混合整数编程。然而我们考虑的机器学习算法，构造一个完全贝叶斯手段，因他们昂贵的自然必要性以最小化评估的时间。贝叶斯优化策略也被用于调节蒙特卡洛算法的超参数。最近本格斯特拉已经探索了大量优化机器学习算法的策略。他们证明网格搜索策略比随机搜索差，建议使用高斯过程贝叶斯优化以优化一个平方到指数的分布，和TPA。

## 2 高斯过程优先的贝叶斯优化
由于在其他类型的优化中，在贝叶斯优化里，我们感兴趣的是找到一个函数在自变量的某个范围内的最小值，我们会把他作为R^D的自己。让贝叶斯优化和其他过程不同的是他构建了f(x)的一个概率模型，然后推导这个模型以决定下一个评估函数的自变量区间在哪里，同时集成不确定性。关键的逻辑是，使用上一次f(x)评估中所有的可用的信息，而非仅仅依赖于局部梯度和hessian近似。这导致一个能用相对少得多的步骤找到困难非凸函数的最小值的过程，代价是决定下一个要尝试的点需要的计算更多了。当评估f(x)执行起来很昂贵的时候，也就是需要训练机器学习算法的时候，容易调整一些额外的计算以取得更好的决策，从贝叶斯优化规范注意的大方向上，以及先前工作的回顾看。在这个部分，我们简单地回顾了通常的贝叶斯优化途径，在第三部分我们将讨论我们的创新性贡献。

### 2.1 高斯过程
高斯过程是一个方便而强大的函数优先分布，我们在这里用它作为这个表达式：f：X -> R。高斯过程由任意有限N个点的集合{Xn ∈ X}定义，推导出多变量的RN空间上的高斯分布。第n个点被作为f(xn)的函数值，高斯分布优雅的边缘化属性允许我们计算边缘，以闭合的形式计算各种情况。函数结果的分布的支持和属性由一个平均函数m: X -> R决定，以及一个正定分布函数K: X * X -> R。我们会在section3.1 讨论分布函数的影响。作为高斯过程的一个概览，参考Rasmussen和Williams。

### 2.2 贝叶斯优化的获取函数
我们假设函数f(x)有一个高斯过程优先绘制，我们的的观察是{Xn, yn}的形式，yn ~ N(f(xn), v), v是引入函数观察中的噪声的方差。这个优先因子和这些数据导出了一个函数的落后因子，也就是获取函数，我们定义为a：X->R+，通过一个代理优化Xnext = argmax(a(x))决定了X中的哪些点需要在下一次评估，并且多个不同的函数已被得到推荐。通常，这些获取函数依赖于先前的观察，包括GP超参数，我们定义这种以来为a(x;{Xn,yn}, θ)。有几种流行的获取函数的选择。在高斯过程优先中，这些函数仅仅通过预测均值函数μ(X; {Xn,yn}, θ)和预测方差函数对函数依赖于模型。在处理过程中，我们将会定义最好的当前值为Xbest = argminxn f(xn), 以及用标准格式定义累计分布函数为Φ(·)。

**提升的可能性** 一种直观的策略是在当前的最佳值之上最大化提升概率。在GP的情况下，这种情况可以分析计算：

> 原文第三页2.2 

**期望提升** 另一种可选图形，我们可以选择在当前最佳值上获得最大化期望提升。这在高斯过程下也有闭合形式。

> 原文第三页2.2 

**GP上置信度** 一个最近的发展是，探索更低的置信边界（上界，认为是最值）以构建最小化优化过程中最小化反悔程度的函数。这类获取函数有着这样的形式：

> 原文第三页2.2 

有着可调的k以平衡操作与探索。

在这篇文章中我们会关注EI标准，因为它被证明比概率可能性要好，但不像GP上置信度，它不需要有自己的调节参数，尽管EI算法在最小化问题上运行得很好，我们希望记下反悔形式可能在某些设置下更加适合。我们在Setion4.1做了基于EI和GP-UCB的比较。


## 3 贝叶斯优化超参数的实践考虑
尽管我们希望有一个优化昂贵函数的优雅框架，但有许多因素限制它成为一个在机器学习问题上优化超参数广泛使用的技术。首先，对于实际问题，分布函数和相关的超参数的合适选择是什么是不确定的。其次，因为函数评估本身可能包括耗时的优化过程，不同问题在耗时上可能有很大的不同，而这在框架设计上也值得考虑。第三，优化算法必须利用多核并行思想，以良好匹配现代计算环境。在本节中，我们提供这三个问题的解决措施。

### 3.1 分布函数以及对分布超参数的处理
高斯过程表达函数复杂分布的能力仅仅依赖于分布函数。而非退化分布函数对应无线基线，它们不会与强假设关于相似函数对应。特别的，自动相关决策平方指数内核：

> 原文第三页3.1 （4）

经常是高斯过程回归的默认选择。然而，这样的分布函数的采样函数对与实际优化问题不现实地慢。想法，我们使用ARD matern 5/2 内核：

> 原文第三页3.1 （5）

这个分布函数导致了二分的采样函数，与quasi-Newton方法做出的假设对应，但不需要平方指数平滑。

选择分布形式后，我们必须管理控制行为的超参数（这些超参数与其他全贝叶斯优化有区别），也必须管理均值。对于我们感兴趣的问题，通常我们有D + 3个高斯过程超参数： D是θ1:D的长度，分布的振幅为θ0，观察噪声v，常量均值m。最常见的主张的途径是通过在高斯过程中，优化边缘可能性，使用一个点来估计这些超参数, p(y | {x n } N
n=1 , θ, ν, m) = N (y | m1, Σ θ + νI), y = [y 1 , y 2 , · · · , y N ] T,Σ θ是N个输入点在超参数θ下的分布矩阵。

然而，对于全贝叶斯超参数处理来说，用超参数优化边缘，计算集成获取函数是必要的：


> 原文第四页 (6)

â(x ; {x n , y n }) = a(x ; {x n , y n }, θ) p(θ | {x n , y n } N n=1 ) dθ,

a(x)依赖于θ和所有观察。对于概率提升和期望提升，这些提升对于超参数的不确定是正确的泛化。我们因此可以根据高斯过程超参数获得的采样结果调整获取函数，并对集成期望提升做蒙特卡洛估计。这些采样可以用切片采样高效地获得，优化和蒙特卡洛计算都比解决N维线性问题多立方倍的代价，经验告诉我们全贝叶斯处理更加合适。图1展示了集成期望提升是如何改变获取函数的。



